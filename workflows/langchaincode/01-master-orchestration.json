{
  "name": "Master Orchestration Agent",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "master/orchestrate",
        "options": {}
      },
      "id": "webhook-master",
      "name": "Master Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [160, 304],
      "webhookId": "master-orchestration"
    },
    {
      "parameters": {
        "jsCode": "// Master Orchestration Agent - Production Implementation\nconst { ChatOpenAI } = require(\"@langchain/openai\");\nconst { AgentExecutor, createOpenAIFunctionsAgent } = require(\"langchain/agents\");\nconst { DynamicTool } = require(\"@langchain/core/tools\");\nconst { PromptTemplate } = require(\"@langchain/core/prompts\");\n\n// Initialize LangSmith tracing\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = process.env.LANGCHAIN_PROJECT || \"athenai-master-orchestrator\";\nprocess.env.LANGCHAIN_ENDPOINT = process.env.LANGCHAIN_ENDPOINT || \"https://api.smith.langchain.com\";\n\nasync function executeMasterOrchestrator() {\n  try {\n    const inputData = $json;\n    const originalMessage = inputData.message;\n    const sessionId = inputData.sessionId || 'default_session';\n    const userId = inputData.userId || 'anonymous';\n    \n    if (!originalMessage) {\n      throw new Error('Message is required for orchestration');\n    }\n\n    // Initialize OpenAI with credentials\n    const llm = new ChatOpenAI({\n      modelName: \"gpt-4\",\n      temperature: 0.2,\n      openAIApiKey: $credentials.openAi?.apiKey || process.env.OPENAI_API_KEY,\n      tags: [\"master-orchestrator\", \"athenai\"]\n    });\n\n    // Create orchestration prompt\n    const orchestrationPrompt = `You are the Master Orchestration Agent for AthenAI. Analyze this user request and create a detailed execution plan.\n\nUser Request: \"${originalMessage}\"\n\nRespond with valid JSON containing:\n- plan: array of execution steps\n- primary_agent: string (research/analysis/creative/development/planning/qa)\n- collaborators: array of supporting agents\n- queue: string (agent_tasks)\n- metadata: object with complexity, estimated_duration, priority\n\nExample response:\n{\n  \"plan\": [\n    {\"step\": 1, \"action\": \"analyze_request\", \"agent\": \"research\", \"description\": \"Initial analysis\"}\n  ],\n  \"primary_agent\": \"research\",\n  \"collaborators\": [\"analysis\"],\n  \"queue\": \"agent_tasks\",\n  \"metadata\": {\"complexity\": \"medium\", \"estimated_duration\": \"30s\", \"priority\": \"normal\"}\n}`;\n\n    // Get orchestration plan from OpenAI\n    const response = await llm.invoke(orchestrationPrompt);\n    let orchestrationPlan;\n    \n    try {\n      orchestrationPlan = JSON.parse(response.content);\n    } catch (e) {\n      // Create default plan if parsing fails\n      orchestrationPlan = {\n        plan: [\n          {\n            step: 1,\n            action: \"analyze_request\",\n            agent: \"research\",\n            description: \"Analyze the user request and gather initial information\"\n          },\n          {\n            step: 2,\n            action: \"generate_response\",\n            agent: \"creative\",\n            description: \"Generate a comprehensive response based on analysis\"\n          }\n        ],\n        primary_agent: \"research\",\n        collaborators: [\"creative\"],\n        queue: \"agent_tasks\",\n        metadata: {\n          complexity: \"medium\",\n          estimated_duration: \"30s\",\n          priority: \"normal\"\n        }\n      };\n    }\n\n    // Validate and enhance plan\n    const taskComplexity = analyzeTaskComplexity(originalMessage);\n    const agentRouting = determineAgentRouting(originalMessage, taskComplexity);\n    \n    // Update plan based on analysis\n    orchestrationPlan.plan = createDetailedPlan(originalMessage, taskComplexity, agentRouting);\n    orchestrationPlan.primary_agent = agentRouting.primary;\n    orchestrationPlan.collaborators = agentRouting.collaborators;\n    orchestrationPlan.metadata.complexity = taskComplexity.level;\n    orchestrationPlan.metadata.estimated_duration = taskComplexity.estimatedDuration;\n\n    // Create execution context\n    const executionContext = {\n      orchestration_id: generateExecutionId(),\n      session_id: sessionId,\n      user_id: userId,\n      original_message: originalMessage,\n      plan: orchestrationPlan.plan,\n      primary_agent: orchestrationPlan.primary_agent,\n      collaborators: orchestrationPlan.collaborators,\n      created_at: new Date().toISOString(),\n      status: \"queued\"\n    };\n\n    return [{\n      json: {\n        orchestration: orchestrationPlan,\n        execution_context: executionContext,\n        routing: {\n          queue: orchestrationPlan.queue,\n          priority: orchestrationPlan.metadata.priority || \"normal\"\n        },\n        neo4j_context: {\n          write: true,\n          cypher: `MERGE (s:Session {id: '${sessionId}'}) MERGE (u:User {id: '${userId}'}) MERGE (r:Request {message: '${originalMessage.replace(/'/g, \"\\\\'\"))}', timestamp: datetime()}) MERGE (s)-[:HAS_REQUEST]->(r) MERGE (u)-[:OWNS_SESSION]->(s)`\n        },\n        memory: {\n          upsert: true,\n          keys: [\"message\", \"timestamp\", \"session_id\", \"user_id\"]\n        },\n        metadata: orchestrationPlan.metadata,\n        timestamp: new Date().toISOString()\n      }\n    }];\n\n  } catch (error) {\n    return [{\n      json: {\n        error: error.message,\n        timestamp: new Date().toISOString(),\n        fallback_plan: {\n          plan: [{\n            step: 1,\n            action: \"error_response\",\n            agent: \"creative\",\n            description: \"Provide error response to user\"\n          }],\n          primary_agent: \"creative\",\n          collaborators: [],\n          queue: \"agent_tasks\"\n        }\n      }\n    }];\n  }\n}\n\n// Task complexity analysis\nfunction analyzeTaskComplexity(message) {\n  const indicators = {\n    length: message.length,\n    questions: (message.match(/\\?/g) || []).length,\n    keywords: extractKeywords(message),\n    technicalTerms: countTechnicalTerms(message),\n    requestTypes: identifyRequestTypes(message)\n  };\n\n  let complexityScore = 0;\n  \n  if (indicators.length > 200) complexityScore += 2;\n  else if (indicators.length > 100) complexityScore += 1;\n  \n  complexityScore += Math.min(indicators.questions * 0.5, 2);\n  complexityScore += Math.min(indicators.technicalTerms * 0.3, 2);\n  complexityScore += indicators.requestTypes.complexity;\n\n  let level, estimatedDuration;\n  if (complexityScore <= 2) {\n    level = \"low\";\n    estimatedDuration = \"15s\";\n  } else if (complexityScore <= 4) {\n    level = \"medium\";\n    estimatedDuration = \"30s\";\n  } else {\n    level = \"high\";\n    estimatedDuration = \"60s\";\n  }\n\n  return {\n    score: complexityScore,\n    level: level,\n    estimatedDuration: estimatedDuration,\n    indicators: indicators\n  };\n}\n\n// Agent routing determination\nfunction determineAgentRouting(message, complexity) {\n  const messageLower = message.toLowerCase();\n  const routing = {\n    primary: \"research\",\n    collaborators: [],\n    reasoning: \"\"\n  };\n\n  if (messageLower.includes(\"research\") || messageLower.includes(\"find\") || \n      messageLower.includes(\"search\") || messageLower.includes(\"information\")) {\n    routing.primary = \"research\";\n    routing.collaborators = [\"analysis\"];\n    routing.reasoning = \"Research request detected\";\n  }\n  else if (messageLower.includes(\"create\") || messageLower.includes(\"write\") || \n           messageLower.includes(\"generate\") || messageLower.includes(\"design\")) {\n    routing.primary = \"creative\";\n    routing.collaborators = [\"research\"];\n    routing.reasoning = \"Creative task detected\";\n  }\n  else if (messageLower.includes(\"code\") || messageLower.includes(\"program\") || \n           messageLower.includes(\"develop\") || messageLower.includes(\"build\")) {\n    routing.primary = \"development\";\n    routing.collaborators = [\"research\", \"qa\"];\n    routing.reasoning = \"Development task detected\";\n  }\n  else if (messageLower.includes(\"analyze\") || messageLower.includes(\"data\") || \n           messageLower.includes(\"statistics\") || messageLower.includes(\"trends\")) {\n    routing.primary = \"analysis\";\n    routing.collaborators = [\"research\"];\n    routing.reasoning = \"Analysis task detected\";\n  }\n  else if (messageLower.includes(\"plan\") || messageLower.includes(\"strategy\") || \n           messageLower.includes(\"organize\") || messageLower.includes(\"schedule\")) {\n    routing.primary = \"planning\";\n    routing.collaborators = [\"research\", \"analysis\"];\n    routing.reasoning = \"Planning task detected\";\n  }\n\n  if (complexity.level === \"high\" && !routing.collaborators.includes(\"qa\")) {\n    routing.collaborators.push(\"qa\");\n  }\n\n  return routing;\n}\n\n// Create detailed execution plan\nfunction createDetailedPlan(message, complexity, routing) {\n  const basePlan = [\n    {\n      step: 1,\n      action: \"analyze_request\",\n      agent: routing.primary,\n      description: `Initial analysis using ${routing.primary} agent`,\n      estimated_duration: \"10s\",\n      dependencies: []\n    }\n  ];\n\n  let stepCounter = 2;\n\n  if (routing.primary !== \"research\" && routing.collaborators.includes(\"research\")) {\n    basePlan.push({\n      step: stepCounter++,\n      action: \"gather_information\",\n      agent: \"research\",\n      description: \"Gather relevant information and context\",\n      estimated_duration: \"15s\",\n      dependencies: [1]\n    });\n  }\n\n  if (routing.collaborators.includes(\"analysis\")) {\n    basePlan.push({\n      step: stepCounter++,\n      action: \"analyze_data\",\n      agent: \"analysis\",\n      description: \"Analyze gathered data and identify patterns\",\n      estimated_duration: \"10s\",\n      dependencies: [stepCounter - 2]\n    });\n  }\n\n  if (routing.primary === \"creative\" || routing.collaborators.includes(\"creative\")) {\n    basePlan.push({\n      step: stepCounter++,\n      action: \"generate_content\",\n      agent: \"creative\",\n      description: \"Generate creative content based on analysis\",\n      estimated_duration: \"15s\",\n      dependencies: [stepCounter - 2]\n    });\n  }\n\n  if (routing.primary === \"development\" || routing.collaborators.includes(\"development\")) {\n    basePlan.push({\n      step: stepCounter++,\n      action: \"develop_solution\",\n      agent: \"development\",\n      description: \"Develop technical solution or code\",\n      estimated_duration: \"20s\",\n      dependencies: [stepCounter - 2]\n    });\n  }\n\n  if (routing.collaborators.includes(\"qa\")) {\n    basePlan.push({\n      step: stepCounter++,\n      action: \"quality_assurance\",\n      agent: \"qa\",\n      description: \"Review and validate output quality\",\n      estimated_duration: \"10s\",\n      dependencies: [stepCounter - 2]\n    });\n  }\n\n  basePlan.push({\n    step: stepCounter,\n    action: \"synthesize_response\",\n    agent: routing.primary,\n    description: \"Synthesize final response from all agent outputs\",\n    estimated_duration: \"10s\",\n    dependencies: [stepCounter - 1]\n  });\n\n  return basePlan;\n}\n\n// Helper functions\nfunction extractKeywords(text) {\n  const words = text.toLowerCase()\n    .replace(/[^\\w\\s]/g, ' ')\n    .split(/\\s+/)\n    .filter(word => word.length > 3);\n  \n  const stopWords = new Set([\n    'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', \n    'of', 'with', 'by', 'this', 'that', 'these', 'those', 'is', 'are', \n    'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', \n    'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might'\n  ]);\n  \n  return words.filter(word => !stopWords.has(word)).slice(0, 10);\n}\n\nfunction countTechnicalTerms(text) {\n  const technicalTerms = [\n    'algorithm', 'api', 'database', 'function', 'variable', 'code', 'programming',\n    'software', 'hardware', 'network', 'server', 'client', 'framework', 'library',\n    'machine learning', 'artificial intelligence', 'data science', 'analytics'\n  ];\n  \n  const textLower = text.toLowerCase();\n  return technicalTerms.filter(term => textLower.includes(term)).length;\n}\n\nfunction identifyRequestTypes(text) {\n  const textLower = text.toLowerCase();\n  let complexity = 0;\n  const types = [];\n\n  if (textLower.includes(\"explain\") || textLower.includes(\"how\")) {\n    types.push(\"explanation\");\n    complexity += 1;\n  }\n  \n  if (textLower.includes(\"create\") || textLower.includes(\"generate\")) {\n    types.push(\"creation\");\n    complexity += 2;\n  }\n  \n  if (textLower.includes(\"analyze\") || textLower.includes(\"compare\")) {\n    types.push(\"analysis\");\n    complexity += 2;\n  }\n  \n  if (textLower.includes(\"solve\") || textLower.includes(\"fix\")) {\n    types.push(\"problem_solving\");\n    complexity += 3;\n  }\n\n  return { types, complexity };\n}\n\nfunction generateExecutionId() {\n  return `exec_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n}\n\n// Execute and return\nreturn await executeMasterOrchestrator();"
      },
      "type": "@n8n/n8n-nodes-langchain.code",
      "typeVersion": 1,
      "position": [360, 304],
      "id": "langchain-orchestrator",
      "name": "Master Orchestrator"
    },
    {
      "parameters": {
        "queue": "={{ $json.routing.queue }}",
        "options": {
          "priority": "={{ $json.routing.priority }}"
        }
      },
      "id": "rabbitmq-publish",
      "name": "RabbitMQ Publish",
      "type": "n8n-nodes-base.rabbitmq",
      "typeVersion": 1,
      "position": [560, 304]
    },
    {
      "parameters": {
        "query": "={{ $json.neo4j_context.cypher }}",
        "additionalFields": {}
      },
      "id": "neo4j-write",
      "name": "Neo4j Write",
      "type": "n8n-nodes-base.neo4j",
      "typeVersion": 1,
      "position": [760, 304]
    },
    {
      "parameters": {
        "operation": "insert",
        "table": "orchestration_memory",
        "columns": "session_id, user_id, message, orchestration_plan, timestamp",
        "values": "={{ $json.execution_context.session_id }}, {{ $json.execution_context.user_id }}, {{ $json.execution_context.original_message }}, {{ JSON.stringify($json.orchestration) }}, {{ $json.timestamp }}"
      },
      "id": "postgres-memory",
      "name": "PostgreSQL Memory",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [960, 304]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {}
      },
      "id": "webhook-response",
      "name": "Webhook Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1160, 304]
    }
  ],
  "pinData": {},
  "connections": {
    "Master Webhook": {
      "main": [
        [
          {
            "node": "Master Orchestrator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Master Orchestrator": {
      "main": [
        [
          {
            "node": "RabbitMQ Publish",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "RabbitMQ Publish": {
      "main": [
        [
          {
            "node": "Neo4j Write",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Neo4j Write": {
      "main": [
        [
          {
            "node": "PostgreSQL Memory",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PostgreSQL Memory": {
      "main": [
        [
          {
            "node": "Webhook Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  }
}
