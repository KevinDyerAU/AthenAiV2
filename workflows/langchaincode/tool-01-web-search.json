{
  "name": "Web Search Tool",
  "nodes": [
    {
      "parameters": {
        "queue": "web_search_requests",
        "options": {}
      },
      "id": "rabbitmq-consume",
      "name": "RabbitMQ Consumer",
      "type": "n8n-nodes-base.rabbitmqTrigger",
      "typeVersion": 1,
      "position": [160, 304]
    },
    {
      "parameters": {
        "jsCode": "// Web Search Tool - Production Implementation\nconst { ChatOpenAI } = require(\"@langchain/openai\");\nconst { SerpAPI } = require(\"@langchain/community/tools/serpapi\");\n\n// Initialize LangSmith tracing\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = process.env.LANGCHAIN_PROJECT || \"athenai-web-search-tool\";\nprocess.env.LANGCHAIN_ENDPOINT = process.env.LANGCHAIN_ENDPOINT || \"https://api.smith.langchain.com\";\n\nasync function executeWebSearch() {\n  try {\n    const inputData = $json;\n    const searchQuery = inputData.query || inputData.search_query;\n    const searchType = inputData.search_type || 'general';\n    const maxResults = inputData.max_results || 10;\n    const sessionId = inputData.session_id || 'default_session';\n    const toolRequestId = inputData.tool_request_id || generateRequestId();\n    \n    if (!searchQuery) {\n      throw new Error('Search query is required');\n    }\n\n    // Initialize search tools\n    const searchResults = await performWebSearch(searchQuery, searchType, maxResults);\n    \n    // Process and rank results\n    const processedResults = await processSearchResults(searchResults, searchQuery);\n    \n    // Generate search summary\n    const searchSummary = await generateSearchSummary(processedResults, searchQuery);\n\n    const searchReport = {\n      tool_request_id: toolRequestId,\n      session_id: sessionId,\n      tool_type: \"web_search\",\n      query: searchQuery,\n      search_type: searchType,\n      results: processedResults,\n      summary: searchSummary,\n      total_results: processedResults.length,\n      search_quality: calculateSearchQuality(processedResults, searchQuery),\n      timestamp: new Date().toISOString(),\n      status: \"completed\"\n    };\n\n    return [{\n      json: {\n        search_report: searchReport,\n        formatted_results: formatSearchResults(processedResults),\n        next_actions: determineSearchNextActions(processedResults, searchQuery),\n        neo4j_context: {\n          write: true,\n          cypher: `MERGE (s:Session {id: '${sessionId}'}) MERGE (sr:SearchRequest {id: '${toolRequestId}', query: '${searchQuery.replace(/'/g, \"\\\\'\"))}', timestamp: datetime(), results_count: ${processedResults.length}}) MERGE (s)-[:PERFORMED_SEARCH]->(sr)`\n        },\n        memory: {\n          upsert: true,\n          keys: [\"query\", \"results\", \"summary\", \"timestamp\"]\n        },\n        routing: {\n          queue: \"tool_results\",\n          priority: \"normal\"\n        }\n      }\n    }];\n\n  } catch (error) {\n    return [{\n      json: {\n        error: error.message,\n        tool_type: \"web_search\",\n        status: \"failed\",\n        timestamp: new Date().toISOString(),\n        fallback_results: {\n          message: \"Web search failed. Manual search may be required.\",\n          suggestions: [\n            \"Check API key configuration\",\n            \"Verify network connectivity\",\n            \"Try alternative search terms\"\n          ]\n        }\n      }\n    }];\n  }\n}\n\n// Perform web search using multiple sources\nasync function performWebSearch(query, searchType, maxResults) {\n  const results = [];\n  \n  try {\n    // Primary search using SerpAPI (Google)\n    if (process.env.SERPAPI_API_KEY || $credentials.serpApi?.apiKey) {\n      const serpApi = new SerpAPI(process.env.SERPAPI_API_KEY || $credentials.serpApi?.apiKey, {\n        hl: \"en\",\n        gl: \"us\",\n        num: Math.min(maxResults, 10)\n      });\n      \n      const serpResults = await serpApi.call(query);\n      const parsedResults = parseSerpResults(serpResults);\n      results.push(...parsedResults);\n    }\n    \n    // Fallback to Bing Search if available\n    if (results.length === 0 && (process.env.BING_SEARCH_API_KEY || $credentials.bingSearch?.apiKey)) {\n      const bingResults = await performBingSearch(query, maxResults);\n      results.push(...bingResults);\n    }\n    \n    // Last resort: DuckDuckGo search (no API key required)\n    if (results.length === 0) {\n      const ddgResults = await performDuckDuckGoSearch(query, maxResults);\n      results.push(...ddgResults);\n    }\n    \n  } catch (error) {\n    console.error('Search error:', error);\n    // Return empty results array instead of throwing\n    return [];\n  }\n  \n  return results.slice(0, maxResults);\n}\n\n// Parse SerpAPI results\nfunction parseSerpResults(serpResults) {\n  const results = [];\n  \n  try {\n    const data = typeof serpResults === 'string' ? JSON.parse(serpResults) : serpResults;\n    \n    if (data.organic_results) {\n      for (const result of data.organic_results) {\n        results.push({\n          title: result.title || 'No title',\n          url: result.link || '',\n          snippet: result.snippet || '',\n          source: 'google',\n          position: result.position || 0,\n          relevance_score: calculateRelevanceScore(result)\n        });\n      }\n    }\n    \n    if (data.news_results) {\n      for (const result of data.news_results) {\n        results.push({\n          title: result.title || 'No title',\n          url: result.link || '',\n          snippet: result.snippet || '',\n          source: 'google_news',\n          date: result.date || '',\n          relevance_score: calculateRelevanceScore(result)\n        });\n      }\n    }\n    \n  } catch (error) {\n    console.error('Error parsing SerpAPI results:', error);\n  }\n  \n  return results;\n}\n\n// Perform Bing search\nasync function performBingSearch(query, maxResults) {\n  try {\n    const apiKey = process.env.BING_SEARCH_API_KEY || $credentials.bingSearch?.apiKey;\n    const endpoint = 'https://api.bing.microsoft.com/v7.0/search';\n    \n    const response = await fetch(`${endpoint}?q=${encodeURIComponent(query)}&count=${maxResults}`, {\n      headers: {\n        'Ocp-Apim-Subscription-Key': apiKey\n      }\n    });\n    \n    if (!response.ok) {\n      throw new Error(`Bing API error: ${response.status}`);\n    }\n    \n    const data = await response.json();\n    const results = [];\n    \n    if (data.webPages && data.webPages.value) {\n      for (const result of data.webPages.value) {\n        results.push({\n          title: result.name || 'No title',\n          url: result.url || '',\n          snippet: result.snippet || '',\n          source: 'bing',\n          relevance_score: 0.8 // Default score for Bing results\n        });\n      }\n    }\n    \n    return results;\n    \n  } catch (error) {\n    console.error('Bing search error:', error);\n    return [];\n  }\n}\n\n// Perform DuckDuckGo search (fallback)\nasync function performDuckDuckGoSearch(query, maxResults) {\n  try {\n    // Note: This is a simplified implementation\n    // In production, you might want to use a proper DuckDuckGo API wrapper\n    const searchUrl = `https://api.duckduckgo.com/?q=${encodeURIComponent(query)}&format=json&no_html=1&skip_disambig=1`;\n    \n    const response = await fetch(searchUrl);\n    if (!response.ok) {\n      throw new Error(`DuckDuckGo API error: ${response.status}`);\n    }\n    \n    const data = await response.json();\n    const results = [];\n    \n    if (data.RelatedTopics) {\n      for (const topic of data.RelatedTopics.slice(0, maxResults)) {\n        if (topic.Text && topic.FirstURL) {\n          results.push({\n            title: topic.Text.split(' - ')[0] || 'No title',\n            url: topic.FirstURL || '',\n            snippet: topic.Text || '',\n            source: 'duckduckgo',\n            relevance_score: 0.6 // Lower score for DDG results\n          });\n        }\n      }\n    }\n    \n    return results;\n    \n  } catch (error) {\n    console.error('DuckDuckGo search error:', error);\n    return [];\n  }\n}\n\n// Process and rank search results\nasync function processSearchResults(rawResults, query) {\n  const processedResults = [];\n  \n  for (const result of rawResults) {\n    const processed = {\n      ...result,\n      relevance_score: calculateDetailedRelevance(result, query),\n      quality_score: assessResultQuality(result),\n      content_preview: await extractContentPreview(result.url),\n      keywords_matched: findMatchingKeywords(result, query)\n    };\n    \n    processedResults.push(processed);\n  }\n  \n  // Sort by combined relevance and quality score\n  processedResults.sort((a, b) => {\n    const scoreA = (a.relevance_score * 0.7) + (a.quality_score * 0.3);\n    const scoreB = (b.relevance_score * 0.7) + (b.quality_score * 0.3);\n    return scoreB - scoreA;\n  });\n  \n  return processedResults;\n}\n\n// Calculate relevance score\nfunction calculateRelevanceScore(result) {\n  let score = 0.5; // Base score\n  \n  if (result.position && result.position <= 3) score += 0.3;\n  else if (result.position && result.position <= 10) score += 0.2;\n  \n  if (result.snippet && result.snippet.length > 50) score += 0.1;\n  if (result.title && result.title.length > 10) score += 0.1;\n  \n  return Math.min(1.0, score);\n}\n\n// Calculate detailed relevance\nfunction calculateDetailedRelevance(result, query) {\n  const queryWords = query.toLowerCase().split(' ').filter(w => w.length > 2);\n  const titleWords = (result.title || '').toLowerCase().split(' ');\n  const snippetWords = (result.snippet || '').toLowerCase().split(' ');\n  \n  let relevanceScore = 0;\n  let totalWords = queryWords.length;\n  \n  for (const word of queryWords) {\n    if (titleWords.includes(word)) relevanceScore += 0.4;\n    else if (snippetWords.includes(word)) relevanceScore += 0.2;\n  }\n  \n  return Math.min(1.0, relevanceScore / totalWords);\n}\n\n// Assess result quality\nfunction assessResultQuality(result) {\n  let quality = 0.5;\n  \n  // URL quality indicators\n  if (result.url.includes('https://')) quality += 0.1;\n  if (result.url.includes('.edu') || result.url.includes('.gov')) quality += 0.2;\n  if (result.url.includes('.org')) quality += 0.1;\n  \n  // Content quality indicators\n  if (result.snippet && result.snippet.length > 100) quality += 0.1;\n  if (result.title && result.title.length > 20 && result.title.length < 100) quality += 0.1;\n  \n  return Math.min(1.0, quality);\n}\n\n// Extract content preview\nasync function extractContentPreview(url) {\n  try {\n    // Simple content extraction - in production, use a proper scraping service\n    const response = await fetch(url, {\n      headers: {\n        'User-Agent': 'Mozilla/5.0 (compatible; AthenAI-Bot/1.0)'\n      },\n      timeout: 5000\n    });\n    \n    if (!response.ok) return 'Preview not available';\n    \n    const html = await response.text();\n    const textContent = html\n      .replace(/<script[^>]*>.*?<\\/script>/gi, '')\n      .replace(/<style[^>]*>.*?<\\/style>/gi, '')\n      .replace(/<[^>]*>/g, ' ')\n      .replace(/\\s+/g, ' ')\n      .trim()\n      .substring(0, 200);\n    \n    return textContent || 'No preview available';\n    \n  } catch (error) {\n    return 'Preview extraction failed';\n  }\n}\n\n// Find matching keywords\nfunction findMatchingKeywords(result, query) {\n  const queryWords = query.toLowerCase().split(' ').filter(w => w.length > 2);\n  const resultText = `${result.title} ${result.snippet}`.toLowerCase();\n  \n  return queryWords.filter(word => resultText.includes(word));\n}\n\n// Generate search summary\nasync function generateSearchSummary(results, query) {\n  if (results.length === 0) {\n    return {\n      overview: `No results found for query: \"${query}\"`,\n      key_findings: [],\n      source_diversity: 0,\n      quality_assessment: 'No results to assess'\n    };\n  }\n  \n  const sources = [...new Set(results.map(r => r.source))];\n  const avgRelevance = results.reduce((sum, r) => sum + r.relevance_score, 0) / results.length;\n  const topResults = results.slice(0, 3);\n  \n  return {\n    overview: `Found ${results.length} results for \"${query}\" from ${sources.length} different sources`,\n    key_findings: topResults.map(r => r.title),\n    source_diversity: sources.length,\n    average_relevance: avgRelevance,\n    quality_assessment: avgRelevance > 0.7 ? 'High quality results' : avgRelevance > 0.4 ? 'Medium quality results' : 'Lower quality results',\n    top_sources: sources\n  };\n}\n\n// Format search results for display\nfunction formatSearchResults(results) {\n  return results.map((result, index) => ({\n    rank: index + 1,\n    title: result.title,\n    url: result.url,\n    snippet: result.snippet,\n    source: result.source,\n    relevance: Math.round(result.relevance_score * 100) + '%',\n    quality: Math.round(result.quality_score * 100) + '%'\n  }));\n}\n\n// Calculate overall search quality\nfunction calculateSearchQuality(results, query) {\n  if (results.length === 0) return 0;\n  \n  const avgRelevance = results.reduce((sum, r) => sum + r.relevance_score, 0) / results.length;\n  const avgQuality = results.reduce((sum, r) => sum + r.quality_score, 0) / results.length;\n  const diversityScore = [...new Set(results.map(r => r.source))].length / 3; // Normalize to max 3 sources\n  \n  return (avgRelevance * 0.5) + (avgQuality * 0.3) + (Math.min(1, diversityScore) * 0.2);\n}\n\n// Determine next actions based on search results\nfunction determineSearchNextActions(results, query) {\n  const actions = [];\n  \n  if (results.length === 0) {\n    actions.push({\n      action: \"refine_search\",\n      priority: \"high\",\n      description: \"No results found - consider refining search terms\"\n    });\n  } else if (results.length < 3) {\n    actions.push({\n      action: \"expand_search\",\n      priority: \"medium\",\n      description: \"Limited results - consider expanding search scope\"\n    });\n  }\n  \n  const avgRelevance = results.reduce((sum, r) => sum + r.relevance_score, 0) / results.length;\n  if (avgRelevance < 0.5) {\n    actions.push({\n      action: \"improve_relevance\",\n      priority: \"medium\",\n      description: \"Low relevance scores - consider different search terms\"\n    });\n  }\n  \n  if (results.length > 0) {\n    actions.push({\n      action: \"process_results\",\n      priority: \"normal\",\n      description: \"Search completed successfully - results ready for processing\"\n    });\n  }\n  \n  return actions;\n}\n\nfunction generateRequestId() {\n  return `search_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n}\n\n// Execute and return\nreturn await executeWebSearch();"
      },
      "type": "@n8n/n8n-nodes-langchain.code",
      "typeVersion": 1,
      "position": [360, 304],
      "id": "langchain-web-search",
      "name": "Web Search Tool"
    },
    {
      "parameters": {
        "queue": "={{ $json.routing.queue }}",
        "options": {
          "priority": "={{ $json.routing.priority }}"
        }
      },
      "id": "rabbitmq-publish",
      "name": "RabbitMQ Publish",
      "type": "n8n-nodes-base.rabbitmq",
      "typeVersion": 1,
      "position": [560, 304]
    },
    {
      "parameters": {
        "query": "={{ $json.neo4j_context.cypher }}",
        "additionalFields": {}
      },
      "id": "neo4j-write",
      "name": "Neo4j Write",
      "type": "n8n-nodes-base.neo4j",
      "typeVersion": 1,
      "position": [760, 304]
    },
    {
      "parameters": {
        "operation": "insert",
        "table": "search_requests",
        "columns": "tool_request_id, session_id, query, results_count, search_quality, timestamp",
        "values": "={{ $json.search_report.tool_request_id }}, {{ $json.search_report.session_id }}, {{ $json.search_report.query }}, {{ $json.search_report.total_results }}, {{ $json.search_report.search_quality }}, {{ $json.search_report.timestamp }}"
      },
      "id": "postgres-memory",
      "name": "PostgreSQL Memory",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [960, 304]
    }
  ],
  "pinData": {},
  "connections": {
    "RabbitMQ Consumer": {
      "main": [
        [
          {
            "node": "Web Search Tool",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Web Search Tool": {
      "main": [
        [
          {
            "node": "RabbitMQ Publish",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "RabbitMQ Publish": {
      "main": [
        [
          {
            "node": "Neo4j Write",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Neo4j Write": {
      "main": [
        [
          {
            "node": "PostgreSQL Memory",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  }
}
